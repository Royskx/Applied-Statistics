{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25805863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # math library\n",
    "import pandas as pd  # Library to handle databases\n",
    "import matplotlib.pyplot as plt  # Graphic library\n",
    "from scipy import stats  # stat library\n",
    "import statsmodels.api as sm  # statistic modelling library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1309994",
   "metadata": {},
   "source": [
    "## Gaussian confidence interval\n",
    "\n",
    "In the first part of this practical session, we study a real dataset that contains features recorded by 237 Statistics students at the University of Adelaide. In particular, we are interested in the span (distance from tip of thumb to tip of little finger of spread hand) of writing hand, in centimetres. In the dataset this is called `Wr.Hnd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc54644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sm.datasets.get_rdataset(\"survey\", \"MASS\").data\n",
    "Wr_hand = np.array(df['Wr.Hnd'])\n",
    "# span (distance from tip of thumb to tip of little finger of spread hand) of writing hand, in centimetres.\n",
    "# From 237 Statistics I students at the University of Adelaide.\n",
    "Wr_hand = Wr_hand[np.isfinite(Wr_hand)]  # remove any missing data (represented by NaN in python, not a number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbda396",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Plot an histogram of the data and verify that the normal distribution can be proposed to model this dataset by displaying the theoretical density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964ac248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a histogram of Wr_hand\n",
    "# Hint: Use plt.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bab58bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a Q-Q plot to verify normality\n",
    "# Hint: Use sm.qqplot() with appropriate parameters\n",
    "# Remember to specify loc (mean) and scale (std) parameters\n",
    "\n",
    "# Q-Q plot\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14269454",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Suppose that the observations in `Wr_hand` are the realizations of random variables $X_1,\\dots,X_n$ that are i.i.d variables from $\\mathcal{N}(\\mu,\\sigma^2)$ with unknown parameters $\\mu\\in\\mathbb{R}$ and $\\sigma^2>0$.\n",
    "\n",
    "We are interested in knowing the mean span of writing hand, perhaps to design a splint or some glove. Compute a $95\\%$ symmetric confidence interval of $\\mu$ (here $\\sigma^2$ is unknown)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8307d21c",
   "metadata": {},
   "source": [
    "\n",
    "We have that standardized empirical mean follows a student distribution:\n",
    "$$ \\sqrt{n}\\frac{\\overline{X}-\\mu}{\\widehat \\sigma}\\sim \\mathcal{T}(n-1)$$\n",
    "Then,\n",
    "\\begin{align*}\n",
    "\\mathbb{P}\\left( q_{\\alpha/2}<\\sqrt{n}\\frac{\\overline{X}-\\mu}{\\widehat \\sigma}<q_{1-\\alpha/2}\\right)&=\\alpha\\\\\n",
    "&= \\mathbb{P}\\left( -q_{1-\\alpha/2}<\\sqrt{n}\\frac{\\overline{X}-\\mu}{\\widehat \\sigma}<q_{1-\\alpha/2}\\right)\n",
    "\\end{align*}\n",
    "where $q_\\alpha$ is a quantile of student distribution of parameter $n-1$.\n",
    "\n",
    "Simplify by determining the value $a$ allowing to write\n",
    "\\begin{align*}\n",
    "\\mathbb{P}\\left( \\overline{X}-a < \\mu < \\overline{X} + a\\right)=\\alpha\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7c5061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute the 95% confidence interval for mu using Student's t-distribution\n",
    "\n",
    "n = len(Wr_hand)\n",
    "mu_hat = # TODO: Compute sample mean\n",
    "sigma_hat = # TODO: Compute sample standard deviation (use ddof=1)\n",
    "se_hat = # TODO: Compute standard error of the mean\n",
    "alpha = # TODO: Determine alpha for 95% CI\n",
    "\n",
    "# TODO: Find the critical t-value using stats.t.ppf()\n",
    "t_crit =\n",
    "\n",
    "# TODO: Compute the margin of error 'a'\n",
    "a =\n",
    "\n",
    "# TODO: Compute the confidence interval\n",
    "conf_int ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd75ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the result\n",
    "print(\"The mean span of writing hand is %.2Fcm with 0.95 confidence interval of [%.2F, %.2F]\" % (\n",
    "    mu_hat, conf_int[0], conf_int[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44531165",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Now we are interested in knowing the variance of the span of writing hand. Compute a $95\\%$ confidence interval of $\\sigma^2$ (here $\\mu$ is unknown)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dee3cc",
   "metadata": {},
   "source": [
    "We have that the standardized empirical variance follows a chi-squared distribution:\n",
    "$$\\frac{1}{\\sigma^2}\\sum_{i=1}^n (X_i-\\overline{X})^2=\\frac{(n-1)\\widehat{\\sigma}^2}{\\sigma^2} \\sim \\chi^2(n-1) $$\n",
    "\n",
    "Then, we have that\n",
    "$$\\widehat{\\sigma}^2=\\frac{1}{n-1}\\sum_{i=1}^n (X_i-\\overline{X})^2$$\n",
    "and\n",
    "\\begin{align*}\n",
    "\\mathbb{P}\\left( q_{\\alpha/2}<\\frac{(n-1)\\widehat{\\sigma}^2}{\\sigma^2}<q_{1-\\alpha/2}\\right)&=\\alpha\\\\\n",
    "&= \\mathbb{P}\\left( \\frac{(n-1)\\widehat{\\sigma}^2}{q_{1-\\alpha/2}}<\\sigma^2<\\frac{(n-1)\\widehat{\\sigma}^2}{q_{\\alpha/2}}\\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562ff1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute the 95% confidence interval for sigma^2 using chi-squared distribution\n",
    "# Hint: Use stats.chi2.ppf() for quantiles\n",
    "\n",
    "law = stats.chi2\n",
    "conf_int = # TODO: Compute CI using the formula from the theory above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39e3367",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The variance of the span of writing hand is %.2F with 0.95 confidence interval of [%.2F, %.2F].\" % (\n",
    "    sigma_hat ** 2, conf_int[0], conf_int[1]))\n",
    "print(\"Hence, the std of the span of writing hand is %.2F with 0.95 confidence interval of [%.2F, %.2F].\" % (\n",
    "    sigma_hat, np.sqrt(conf_int[0]), np.sqrt(conf_int[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194a8695",
   "metadata": {},
   "source": [
    "## Illustration of CLT on exponential random variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc2b2a2",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "In this question, we do $T=1000$ experiments, in each experiment we begin by sampling according to an exponential of parameter $\\mu = 1$ with sample size $n=5$, then we compute the empirical mean of this sample that we stock them in an array `means`.\n",
    "Finally, we represent the sampling law of the means by an histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268ab3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform T=1000 experiments\n",
    "T = 1000\n",
    "n = 5\n",
    "np.random.seed(42)\n",
    "means = []\n",
    "\n",
    "# TODO: Loop T times, each time:\n",
    "#   1. Generate a sample from exponential distribution (use np.random.exponential)\n",
    "#   2. Compute the mean of the sample\n",
    "#   3. Append to the means list\n",
    "\n",
    "for f in range(T):\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# TODO: Plot histogram of means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d17f62",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "The Central Limit Theorem (CLT) gives the approximate Gaussian distribution of the sample mean, whatever the generative law of the sample. We apply it on an exponential sample.\n",
    "\n",
    "**Recall:** By the CLT, we have\n",
    "$$\\sqrt{n}\\frac{\\bar{X}_n - \\mathbb{E}[X]}{\\sqrt{\\mathrm{Var}(X)}} \\xrightarrow{d} \\mathcal{N}(0,1)$$\n",
    "where $\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i$ is the sample mean.\n",
    "\n",
    "Histograms are not the right tool to visualize complex behavior of a density; instead we will look at the CDF.\n",
    "\n",
    "**Tasks:**\n",
    "1. If the empirical means are stored in `means`, construct a vector `renormalized_means` that contains the values of \n",
    "   $$\\sqrt{n}\\frac{\\bar{X}_n - \\mathbb{E}[X]}{\\sqrt{\\mathrm{Var}(X)}}$$\n",
    "   \n",
    "2. Plot the empirical CDF of `renormalized_means` and the theoretical CDF of the standard normal distribution $\\mathcal{N}(0,1)$.\n",
    "\n",
    "3. Repeat with $n=100$ and plot the associated empirical CDF on the same figure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97216520",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2a6526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for empirical CDF\n",
    "def ecdf(x, sample):\n",
    "    return np.mean(sample <= x)\n",
    "\n",
    "# TODO: For exponential(1), E[X] = 1 and Var(X) = 1\n",
    "# TODO: Renormalize the means using the CLT formula\n",
    "means = np.array(means)\n",
    "xplot = np.linspace(-3, 3)\n",
    "\n",
    "# TODO: Plot theoretical CDF of N(0,1)\n",
    "plt.plot(xplot, stats.norm().cdf(xplot), label='Theoretical cdf')\n",
    "\n",
    "# TODO: Compute renormalized_means and plot empirical CDF\n",
    "renormalized_means = # Your formula here\n",
    "\n",
    "# TODO: Plot empirical CDF\n",
    "plt.plot(xplot, [ecdf(x, renormalized_means) for x in xplot], label='Empirical cdf')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368a3238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Repeat for n=5 and n=100, compare on the same plot\n",
    "xplot = np.linspace(-3, 3)\n",
    "plt.plot(xplot, stats.norm().cdf(xplot), label='Theoretical cdf')\n",
    "\n",
    "for n in [5, 100]:\n",
    "    means = []\n",
    "    # TODO: Generate T samples for each n\n",
    "    for f in range(T):\n",
    "        # Your code here\n",
    "        pass\n",
    "\n",
    "    means = np.array(means)\n",
    "    # TODO: Renormalize and plot\n",
    "    renormalized_means = # Your formula here\n",
    "    plt.plot(xplot, [ecdf(x, renormalized_means) for x in xplot], label='n=' + str(n))\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977af0f7",
   "metadata": {},
   "source": [
    "## Confidence interval based on the CLT\n",
    "\n",
    "In this final part, we study the `quine` dataset from Walgett, New South Wales, Australia. This dataset contains 146 observations of children classified by:\n",
    "- **Eth**: Ethnicity (Aboriginal or Non-Aboriginal)\n",
    "- **Sex**: Gender (Male or Female)  \n",
    "- **Age**: Age group (Primary or Secondary)\n",
    "- **Lrn**: Learner status (Average or Slow learner)\n",
    "- **Days**: Number of days absent from school in a particular school year\n",
    "\n",
    "The variable of interest is `Days`, the number of absence days, which ranges from 0 to 81 with a mean of approximately 16.5 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da8c8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sm.datasets.get_rdataset(\"quine\", \"MASS\").data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd6a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b5d565",
   "metadata": {},
   "source": [
    "The distribution of absence days is right-skewed with a median of 11 days. We will model the `Days` variable using an **exponential distribution**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1f4463",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "Compute a $95\\%$ confidence interval of the mean $\\mu$ of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3509db28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use CLT to compute 95% CI for the mean\n",
    "# Hint: For exponential, we can use CLT with normal approximation\n",
    "# For exponential distribution, SE = mu_hat / sqrt(n)\n",
    "\n",
    "mu_hat = # TODO: Compute sample mean of 'Days'\n",
    "law = stats.norm\n",
    "alpha = # TODO: Set alpha for 95% CI\n",
    "n = # TODO: Get sample size\n",
    "\n",
    "# TODO: Compute confidence interval\n",
    "# Hint: CI = (mu_hat - z * SE, mu_hat + z * SE)\n",
    "conf_int ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20829bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The mean duration of absence for the children is %.2F days with 0.95 confidence interval of [%.2F, %.2F]\" % (\n",
    "    mu_hat, conf_int[0], conf_int[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72c1e8d",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "Suppose that we collect a new dataset from the same population with the same features observed on other children, and that we construct a confidence interval with this data set using the same method. What is the probability that the confidence interval contains the true value of $\\mu$ ? Warning: the confidence interval is random and $\\mu$ is fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2917781f",
   "metadata": {},
   "source": [
    "## Real-World Application: NYC Taxi Trip Duration Analysis\n",
    "\n",
    "In this extended section, we analyze a real-world dataset of NYC taxi trip durations. This exercise demonstrates how to apply confidence interval methods to data that requires transformation and careful interpretation.\n",
    "\n",
    "**Dataset**: NYC Taxi Trip Duration  \n",
    "**Source**: Synthetic data based on realistic patterns from NYC taxi operations  \n",
    "**Size**: 15,000 trip records  \n",
    "\n",
    "**Context**: Understanding trip duration patterns is crucial for:\n",
    "- Ride-hailing app time estimates\n",
    "- Driver earnings projections\n",
    "- Urban traffic planning\n",
    "- Customer experience optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a110757f",
   "metadata": {},
   "source": [
    "### Question 8: Data Loading and Initial Exploration\n",
    "\n",
    "Load the NYC taxi dataset and perform initial exploratory analysis:\n",
    "1. Load the data from `shared/data/nyc-taxi/nyc_taxi_trip_duration.csv`\n",
    "2. Display the first few rows and basic information\n",
    "3. Create a histogram of trip duration (in minutes)\n",
    "4. Compute basic summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce73256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the NYC taxi data\n",
    "taxi_df = # Load from '../../shared/data/nyc-taxi/nyc_taxi_trip_duration.csv'\n",
    "\n",
    "# TODO: Display basic information\n",
    "print(\"Dataset shape:\", taxi_df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "# Display first few rows\n",
    "\n",
    "# TODO: Convert trip duration to minutes for easier interpretation\n",
    "taxi_df['trip_duration_min'] = # Convert from seconds to minutes\n",
    "\n",
    "# TODO: Summary statistics\n",
    "print(\"\\nTrip Duration Summary (in minutes):\")\n",
    "# Display summary statistics\n",
    "\n",
    "# TODO: Create visualizations\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "# TODO: Create histogram with bins=50\n",
    "# TODO: Add vertical lines for mean and median\n",
    "plt.xlabel('Trip Duration (minutes)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of NYC Taxi Trip Durations')\n",
    "plt.legend()\n",
    "\n",
    "# Boxplot\n",
    "plt.subplot(1, 2, 2)\n",
    "# TODO: Create boxplot\n",
    "plt.ylabel('Trip Duration (minutes)')\n",
    "plt.title('Boxplot of Trip Durations')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# TODO: Print observation about skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a188c936",
   "metadata": {},
   "source": [
    "### Question 9: Normality Assessment and Transformation\n",
    "\n",
    "The trip duration distribution is clearly right-skewed. A common approach for positive right-skewed data is to apply a **log-transformation**.\n",
    "\n",
    "**Tasks:**\n",
    "1. Create a QQ-plot comparing the raw trip duration to a normal distribution\n",
    "2. Apply a log-transformation: `log_duration = log(trip_duration)`\n",
    "3. Create a QQ-plot for the log-transformed data\n",
    "4. Compare the two plots and conclude which distribution is more appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba63b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply log transformation first\n",
    "taxi_df['log_duration'] = # Hint: Use np.log() on 'trip_duration'\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# QQ-plot for raw data\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "# TODO: Create QQ-plot for raw trip_duration_min\n",
    "# Hint: Use sm.qqplot() with ax=ax1\n",
    "plt.title('QQ-Plot: Raw Trip Duration')\n",
    "\n",
    "# QQ-plot for log-transformed data\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "# TODO: Create QQ-plot for log_duration\n",
    "plt.title('QQ-Plot: Log-Transformed Duration')\n",
    "\n",
    "# Histogram of log-transformed data\n",
    "plt.subplot(1, 3, 3)\n",
    "# TODO: Create histogram of log_duration with density=True\n",
    "plt.xlabel('Log(Trip Duration)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Log-Transformed Duration')\n",
    "\n",
    "# TODO: Overlay normal distribution fit\n",
    "# Hint: Use stats.norm.pdf() with mean and std of log_duration\n",
    "x = np.linspace(taxi_df['log_duration'].min(), taxi_df['log_duration'].max(), 100)\n",
    "# Plot normal PDF\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# TODO: Print conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd407b7",
   "metadata": {},
   "source": [
    "### Question 10: Confidence Interval for Mean Trip Duration Using CLT\n",
    "\n",
    "Now we'll construct a confidence interval for the **mean log-duration** using the CLT, then transform it back to the original scale.\n",
    "\n",
    "**Background**: When data follows a log-normal distribution $X \\sim \\text{LogNormal}(\\mu, \\sigma^2)$, then $\\log(X) \\sim \\mathcal{N}(\\mu, \\sigma^2)$.\n",
    "\n",
    "**Tasks:**\n",
    "1. Estimate $\\mu$ and $\\sigma^2$ for the log-transformed data\n",
    "2. Construct a 95% confidence interval for $\\mu$ using the CLT\n",
    "3. Transform the CI back to the original scale by exponentiating\n",
    "4. Interpret the result: this gives us a CI for the **geometric mean** of trip duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0d504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample size\n",
    "n = len(taxi_df)\n",
    "\n",
    "# TODO: Estimate parameters for log-duration\n",
    "mu_log = # Mean of log_duration\n",
    "sigma_log = # Standard deviation of log_duration (use ddof=1)\n",
    "se_log = # Standard error\n",
    "\n",
    "# TODO: 95% confidence interval for mu (log scale)\n",
    "alpha = 0.05\n",
    "z_crit = # Critical value for 95% CI\n",
    "ci_log_lower = # Lower bound on log scale\n",
    "ci_log_upper = # Upper bound on log scale\n",
    "\n",
    "print(\"Log-scale parameters:\")\n",
    "print(f\"  μ̂ = {mu_log:.4f}\")\n",
    "print(f\"  σ̂ = {sigma_log:.4f}\")\n",
    "print(f\"  SE(μ̂) = {se_log:.4f}\")\n",
    "print(f\"\\n95% CI for μ (log-scale): [{ci_log_lower:.4f}, {ci_log_upper:.4f}]\")\n",
    "\n",
    "# TODO: Transform back to original scale (geometric mean)\n",
    "# Hint: geometric_mean = exp(mu_log)\n",
    "geometric_mean =\n",
    "ci_original_lower =\n",
    "ci_original_upper =\n",
    "\n",
    "print(f\"\\nGeometric mean trip duration: {geometric_mean:.2f} seconds ({geometric_mean/60:.2f} minutes)\")\n",
    "print(f\"95% CI for geometric mean: [{ci_original_lower:.2f}, {ci_original_upper:.2f}] seconds\")\n",
    "print(f\"                         = [{ci_original_lower/60:.2f}, {ci_original_upper/60:.2f}] minutes\")\n",
    "\n",
    "# TODO: Compare with arithmetic mean\n",
    "arithmetic_mean = taxi_df['trip_duration'].mean()\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  Arithmetic mean: {arithmetic_mean:.2f} seconds ({arithmetic_mean/60:.2f} minutes)\")\n",
    "print(f\"  Geometric mean:  {geometric_mean:.2f} seconds ({geometric_mean/60:.2f} minutes)\")\n",
    "print(f\"  Median:          {taxi_df['trip_duration'].median():.2f} seconds ({taxi_df['trip_duration'].median()/60:.2f} minutes)\")\n",
    "print(f\"\\nNote: For log-normal data, geometric mean < median < arithmetic mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad4bc77",
   "metadata": {},
   "source": [
    "### Question 11: Comparing Rush Hour vs Non-Rush Hour Trips\n",
    "\n",
    "Let's investigate whether rush hour affects trip duration by comparing two groups:\n",
    "- **Rush hour**: Morning (7-9am) and Evening (5-7pm)\n",
    "- **Non-rush hour**: All other times\n",
    "\n",
    "**Tasks:**\n",
    "1. Separate the data into rush hour and non-rush hour groups\n",
    "2. For each group, compute the geometric mean and 95% CI\n",
    "3. Determine if the confidence intervals overlap\n",
    "4. Interpret the practical significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df808e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lognormal_ci(data, alpha=0.05):\n",
    "    \"\"\"Compute CI for geometric mean of log-normally distributed data\"\"\"\n",
    "    # TODO: Complete this function\n",
    "    n = len(data)\n",
    "    log_data = np.log(data)\n",
    "    mu_log = # Mean of log data\n",
    "    sigma_log = # Std of log data (ddof=1)\n",
    "    se_log = # Standard error\n",
    "\n",
    "    z_crit = # Critical z-value\n",
    "    ci_log = # CI on log scale\n",
    "\n",
    "    geometric_mean = # exp(mu_log)\n",
    "    ci_original = # Transform CI back to original scale\n",
    "\n",
    "    return geometric_mean, ci_original, n\n",
    "\n",
    "# TODO: Separate groups based on is_rush_hour column\n",
    "rush_hour_data = # Filter for rush hour trips\n",
    "non_rush_data = # Filter for non-rush hour trips\n",
    "\n",
    "# TODO: Compute CIs for each group\n",
    "gm_rush, ci_rush, n_rush = compute_lognormal_ci(rush_hour_data)\n",
    "gm_non_rush, ci_non_rush, n_non_rush = compute_lognormal_ci(non_rush_data)\n",
    "\n",
    "# Print results\n",
    "print(\"=\"*70)\n",
    "print(\"RUSH HOUR TRIPS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Sample size: {n_rush}\")\n",
    "print(f\"Geometric mean: {gm_rush:.2f} seconds ({gm_rush/60:.2f} minutes)\")\n",
    "print(f\"95% CI: [{ci_rush[0]:.2f}, {ci_rush[1]:.2f}] seconds\")\n",
    "print(f\"      = [{ci_rush[0]/60:.2f}, {ci_rush[1]/60:.2f}] minutes\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NON-RUSH HOUR TRIPS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Sample size: {n_non_rush}\")\n",
    "print(f\"Geometric mean: {gm_non_rush:.2f} seconds ({gm_non_rush/60:.2f} minutes)\")\n",
    "print(f\"95% CI: [{ci_non_rush[0]:.2f}, {ci_non_rush[1]:.2f}] seconds\")\n",
    "print(f\"      = [{ci_non_rush[0]/60:.2f}, {ci_non_rush[1]/60:.2f}] minutes\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "percent_diff = ((gm_rush - gm_non_rush) / gm_non_rush) * 100\n",
    "print(f\"Difference in geometric means: {gm_rush - gm_non_rush:.2f} seconds ({percent_diff:.1f}% longer in rush hour)\")\n",
    "\n",
    "# TODO: Check if CIs overlap\n",
    "if ci_rush[0] > ci_non_rush[1] or ci_non_rush[0] > ci_rush[1]:\n",
    "    print(\"Confidence intervals DO NOT overlap → statistically significant difference\")\n",
    "else:\n",
    "    print(\"Confidence intervals overlap → difference may not be statistically significant\")\n",
    "\n",
    "# TODO: Create visualizations comparing the groups\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "# TODO: Create error bar plot showing geometric means with CIs\n",
    "# Hint: Use plt.errorbar()\n",
    "plt.xticks([1, 2], ['Non-Rush Hour', 'Rush Hour'])\n",
    "plt.ylabel('Trip Duration (minutes)')\n",
    "plt.title('Geometric Mean Trip Duration with 95% CI')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# TODO: Create overlapping histograms\n",
    "plt.xlabel('Trip Duration (minutes)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution Comparison')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e890f9",
   "metadata": {},
   "source": [
    "### Question 12: Practical Interpretation and Recommendations\n",
    "\n",
    "Based on your analysis, answer the following questions:\n",
    "\n",
    "1. **Why is the geometric mean more appropriate than the arithmetic mean for log-normal data?**\n",
    "\n",
    "2. **What would you tell a ride-hailing company about expected trip times?**\n",
    "   - What's a reasonable estimate to show customers?\n",
    "   - Should they adjust estimates during rush hour?\n",
    "\n",
    "3. **Sample size considerations**: \n",
    "   - How would the confidence interval width change with 5,000 trips vs 15,000 trips?\n",
    "   - Use the formula for CI width to explain.\n",
    "\n",
    "4. **Limitations of this analysis**:\n",
    "   - What factors are we not accounting for?\n",
    "   - What additional data would improve the analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6783ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your answers and supporting analysis here\n",
    "\n",
    "# Question 1: Geometric mean vs arithmetic mean\n",
    "# Your answer:\n",
    "\n",
    "# Question 2: Recommendations for ride-hailing company\n",
    "# Your answer:\n",
    "\n",
    "# Question 3: Sample size impact on CI width\n",
    "# TODO: Calculate CI widths for different sample sizes\n",
    "# Hint: CI width ∝ 1/√n\n",
    "sample_sizes = [5000, 15000, 50000]\n",
    "# Your code here\n",
    "\n",
    "# Question 4: Limitations and improvements\n",
    "# Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1484f7e",
   "metadata": {},
   "source": [
    "### Bonus: Sample Size Effect Visualization\n",
    "\n",
    "Visualize how sample size affects confidence interval width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9d5fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Bonus visualization - how sample size affects CI width\n",
    "sample_sizes = [1000, 2000, 5000, 10000, 15000, 20000, 30000]\n",
    "ci_widths = []\n",
    "\n",
    "for n_sample in sample_sizes:\n",
    "    # TODO: Sample from data (with replacement if n_sample > data size)\n",
    "    # TODO: Compute CI using compute_lognormal_ci()\n",
    "    # TODO: Calculate width in minutes and append to ci_widths\n",
    "    pass\n",
    "\n",
    "# TODO: Create plot showing sample size vs CI width\n",
    "plt.figure(figsize=(10, 5))\n",
    "# Your plotting code here\n",
    "plt.xlabel('Sample Size (n)')\n",
    "plt.ylabel('95% CI Width (minutes)')\n",
    "plt.title('How Sample Size Affects Confidence Interval Precision')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key insight: Doubling sample size reduces CI width by factor of √2 ≈ 1.41\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
